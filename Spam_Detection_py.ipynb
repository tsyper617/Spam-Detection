{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Read CSV file and select the first two columns\n",
        "df = pd.read_csv('spam.csv', encoding='latin1', usecols=[0, 1])\n",
        "\n",
        "# Rename the columns\n",
        "df = df.rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "\n",
        "# Check for null values\n",
        "df.isnull().sum()\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    # convert to lowercase\n",
        "    text = text.lower()\n",
        "    # remove special characters\n",
        "    text = re.sub(r'[^0-9a-zA-Z]', ' ', text)\n",
        "    # remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # remove stopwords\n",
        "    text = \" \".join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text\n",
        "\n",
        "# Clean the messages\n",
        "df['clean_text'] = df['message'].apply(clean_text)\n",
        "df.head()\n",
        "\n",
        "X = df['clean_text']  # Use clean text for input\n",
        "y = df['label']  # Use original labels for target variable\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def classify(model, X, y):\n",
        "    # Train-test split\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True, stratify=y)\n",
        "\n",
        "    # Model training\n",
        "    pipeline_model = Pipeline([('vect', CountVectorizer()),\n",
        "                               ('tfidf', TfidfTransformer()),\n",
        "                               ('clf', model)])\n",
        "    pipeline_model.fit(x_train, y_train)\n",
        "\n",
        "    print('Accuracy:', pipeline_model.score(x_test, y_test) * 100)\n",
        "\n",
        "    y_pred = pipeline_model.predict(x_test)\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "\n",
        "    joblib.dump(pipeline_model, 'sms_spam_svc_model.pkl')\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "classify(model, X, y)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "classify(model, X, y)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "thirdmodel = SVC(C=3)\n",
        "classify(model, X, y)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "classify(model, X, y)\n",
        "\n",
        "import joblib\n",
        "import colorama\n",
        "from colorama import Fore, Style\n",
        "\n",
        "colorama.init(autoreset=True)  # Initialize colorama\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = joblib.load('sms_spam_svc_model.pkl', mmap_mode='r')\n",
        "\n",
        "# Read the new CSV file with the messages\n",
        "new_data = pd.read_csv('spamraw.csv')\n",
        "actual_labels = new_data['type']\n",
        "messages = new_data['text']\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "num_messages = 5000\n",
        "correct_predictions = 0\n",
        "\n",
        "for index, (message, label) in enumerate(zip(messages.head(num_messages), actual_labels.head(num_messages))):\n",
        "    cleaned_message = clean_text(message)\n",
        "    prediction = loaded_model.predict([cleaned_message])[0]\n",
        "\n",
        "    if prediction == 'ham':\n",
        "        predicted_label = \"Regular Message\"\n",
        "    else:\n",
        "        predicted_label = \"Spam\"\n",
        "\n",
        "    output = f\"Message {index + 1}: Predicted - {predicted_label}, Actual - {label}\"\n",
        "\n",
        "    if prediction == label:\n",
        "        output = Fore.GREEN + output  # Correct prediction in green\n",
        "        correct_predictions += 1\n",
        "    else:\n",
        "        output = Fore.RED + output    # Incorrect prediction in red\n",
        "\n",
        "    print(output)\n",
        "\n",
        "accuracy = correct_predictions / num_messages * 100\n",
        "print(Fore.CYAN + f\"\\nAccuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mT-xWAAFlpsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}